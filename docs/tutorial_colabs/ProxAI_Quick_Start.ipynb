{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyOyNKDPrfr+1GrHhWdycZPt",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/proxai/proxai/blob/main/docs/tutorial_colabs/ProxAI_Quick_Start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# \ud83c\udfc3\u200d\u2642\ufe0f\u200d\u27a1\ufe0f ProxAI Quick Start Tutorial \ud83c\udfc3\u200d\u2642\ufe0f\u200d\u27a1\ufe0f"
   ],
   "metadata": {
    "id": "pjbMJjs52Muk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## \ud83d\udc4b Introduction\n",
    "\n",
    "Welcome to the ProxAI Quick Start Tutorial! This notebook will guide you through some of the features of the ProxAI library.\n",
    "\n",
    "In this tutorial, we will cover:\n",
    "1. \u26a1\ufe0f Setting up ProxAI in Google Colab\n",
    "2. \ud83d\udd0b List Available Models\n",
    "3. \ud83e\udd16 Generate Text\n",
    "4. \ud83d\udd2e Set Global Model"
   ],
   "metadata": {
    "id": "Cn4yLuib4RC5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. \u26a1\ufe0f Setup in Google Colab\n",
    "Documentation: [proxai.co/proxai-docs](https://www.proxai.co/proxai-docs)"
   ],
   "metadata": {
    "id": "lhUb737sqIIi"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## 1.1. \ud83d\udcbb Installation\n\nFirst, let's install the ProxAI library from PyPI.\n\nYou can track releases on the [roadmap page](https://www.proxai.co/resources/roadmap) \ud83d\uddfa\ufe0f.\n\n**Note:** After running the installation cell, you will likely need to **\ud83d\udd04 restart the Colab session** using the button that appears in the output of the cell or by going to `Runtime > Restart session`.",
   "metadata": {
    "id": "HuNUNooRqOIm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "av5yOW1mqBug",
    "outputId": "5c411ed0-1ea1-49e6-81ca-8ef4fff0fe1b"
   },
   "outputs": [],
   "source": "!pip install proxai"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. \ud83d\udd11 API Key Management\n",
    "\n",
    "ProxAI works with various AI providers. You'll need to add your API keys as secrets in Google Colab. This is the safest way to handle them.\n",
    "\n",
    "1.  Click on the **\ud83d\udd11 icon (Secrets)** in the left sidebar of Colab.\n",
    "2.  Add your API keys with the names ProxAI expects (e.g., `OPENAI_API_KEY`, `GEMINI_API_KEY`, `PROXDASH_API_KEY`, etc.). Refer to the [Provider Integrations documentation](https://www.proxai.co/proxai-docs/provider-integrations) for the full list of environment keys.\n",
    "\n",
    "Run the following cell to load your API keys from Colab secrets into the environment.\n",
    "\n",
    "<div style=\"background-color: #ffebee; border-left: 6px solid #f44336; padding: 10px; margin-bottom: 15px;\">\n",
    "  <p style=\"margin: 0; font-weight: bold; color: #c62828;\">\ud83d\udeab Important Security Note:</p>\n",
    "  <p style=\"margin: 0; color: #c62828;\">Never directly add API key values as string variables inside the Colab cells. Even after deletion, they can be retrieved from the Colab history.</p>\n",
    "</div>"
   ],
   "metadata": {
    "id": "yItxyArt4sK3"
   }
  },
  {
   "cell_type": "code",
   "source": "import os\nfrom google.colab import userdata\nfrom dataclasses import asdict\nfrom pprint import pprint\n\nAPI_KEY_LIST = [\n    'ANTHROPIC_API_KEY',\n    'CO_API_KEY',\n    'DATABRICKS_TOKEN',\n    'DATABRICKS_HOST',\n    'DEEPSEEK_API_KEY',\n    'GEMINI_API_KEY',\n    'XAI_API_KEY',\n    'HF_TOKEN',\n    'MISTRAL_API_KEY',\n    'OPENAI_API_KEY',\n    'PROXDASH_API_KEY',\n]\n\nprint(\"\ud83d\udd10 Attempting to load API keys from Colab secrets...\")\nfor api_key_name in API_KEY_LIST:\n  try:\n    os.environ[api_key_name] = userdata.get(api_key_name)\n    print(f\"  \u2705 Successfully loaded {api_key_name}\")\n  except userdata.SecretNotFoundError:\n    print(f\"  \u26a0\ufe0f Secret for {api_key_name} not found. Skipping.\")\n  except Exception as e:\n    print(f\"  \u274c An error occurred while loading {api_key_name}: {e}\")",
   "metadata": {
    "id": "JUzEyL3PqcN0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c35a5e34-064a-4483-c4d6-c1051ba8889c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3. \u25b6\ufe0f Import ProxAI\n",
    "\n",
    "Ready to go!"
   ],
   "metadata": {
    "id": "rYRptpaO5LVd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import proxai as px"
   ],
   "metadata": {
    "id": "Dsx0B36W5NFe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. \ud83d\udd0b List Available Models\n",
    "\n",
    "Documentation: [proxai.co/proxai-docs/available-models](https://www.proxai.co/proxai-docs/available-models)"
   ],
   "metadata": {
    "id": "SDHnRjkW5Ph5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1. \ud83e\ude9b Simple Usage\n",
    "\n",
    "Let's list available models in our session! \ud83c\udf89 \\\n",
    "**Note:** This can take for a while for the first run but the results are cached and it will be fast for other runs."
   ],
   "metadata": {
    "id": "jB_CFueU5RUy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "provider_models = px.models.list_models()\n",
    "for provider_model in provider_models:\n",
    "  print(f'{provider_model}')"
   ],
   "metadata": {
    "id": "JAwC8WLW5TZv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "092b97e5-5c35-418d-88d6-147397f4e02f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2. \ud83d\udd2d Different Model Sizes\n",
    "\n",
    "It is possible to filter out models according to ProxAI sizes."
   ],
   "metadata": {
    "id": "9dAVv5Ld5VAN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "provider_models = px.models.list_models(model_size='small')\n",
    "print('\ud83e\udd5a Small models:')\n",
    "for provider_model in provider_models:\n",
    "  print(f'{provider_model.provider:>25} - {provider_model.model}')\n",
    "\n",
    "provider_models = px.models.list_models(model_size='medium')\n",
    "print('\ud83d\udc23 Medium models:')\n",
    "for provider_model in provider_models:\n",
    "  print(f'{provider_model.provider:>25} - {provider_model.model}')\n",
    "\n",
    "provider_models = px.models.list_models(model_size='large')\n",
    "print('\ud83d\udc25 Large models:')\n",
    "for provider_model in provider_models:\n",
    "  print(f'{provider_model.provider:>25} - {provider_model.model}')\n",
    "\n",
    "provider_models = px.models.list_models(model_size='largest')\n",
    "print('\ud83d\udc13 Largest models of each provider:')\n",
    "for provider_model in provider_models:\n",
    "  print(f'{provider_model.provider:>25} - {provider_model.model}')"
   ],
   "metadata": {
    "id": "Z3zKDEnV5Vfs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fe5af2b0-745f-4166-b626-d7cafbb2568b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. \ud83e\udd16 Generate Text\n",
    "\n",
    "Documentation: [proxai.co/proxai-docs/generate-text](https://www.proxai.co/proxai-docs/generate-text)"
   ],
   "metadata": {
    "id": "fevDRQa65jOa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1. \ud83d\udc36 The Simplest Usage\n",
    "\n",
    "You can directly call `px.generate_text()` without any additional paramters. ProxAI picks default model or fallback models if default model is not working."
   ],
   "metadata": {
    "id": "98ExB5P65jz-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "response = px.generate_text('Hello! Which model are you?')\n",
    "print(response)"
   ],
   "metadata": {
    "id": "BiJcBYYp5oCJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6b40bbe1-467e-488b-e74a-f027b0acbcff"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2. \u270f\ufe0f Setting Provider Model\n",
    "\n",
    "You can specify `provider_model` parameter for `px.generate_text()` as `(provider, model)` tuple of strings.\n",
    "* Check [Provider Integrations documentation](https://www.proxai.co/proxai-docs/provider-integrations) to see all available models."
   ],
   "metadata": {
    "id": "xtJSwNzV5tZN"
   }
  },
  {
   "cell_type": "code",
   "source": "print('\u270f\ufe0f Tuple provider_model value:')\nresponse = px.generate_text(\n    'Hello! Which model are you?',\n    provider_model=('claude', 'haiku-4.5'))\nprint(response)",
   "metadata": {
    "id": "KlqvKC7R5uHY",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "17113150-e4ad-45fc-f07a-9d1283c30d0a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3. \ud83d\udcac Additional Features\n",
    "\n",
    "You can use `system`, `messages`, `temperature`, `stop`, and many more on `px.generate_text()`.\n",
    "* Check [Generate Text documentation](https://www.proxai.co/proxai-docs/generate-text) to see all available options."
   ],
   "metadata": {
    "id": "4rOS-GeJ6V8V"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "response = px.generate_text(\n",
    "    system=\"Try to impersonate Italian America Chef. Try to use lot's of italian words.\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello AI Model!\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Buongiorno!\"},\n",
    "        {\"role\": \"user\", \"content\": \"How are you today?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Molto Bene! How are you amico?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you recomend me Italian restaurants in NYC?\"}\n",
    "    ],\n",
    "    max_tokens=1000,\n",
    "    temperature=0.7,\n",
    "    stop=[\"\\n\"],\n",
    ")\n",
    "print(response)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2dgwvr57HE9",
    "outputId": "314d2d52-cf04-48a6-f818-993dc04a1c25"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. \ud83d\udd2e Set Global Model\n",
    "\n",
    "Documentation: [proxai.co/proxai-docs/set-global-model](https://www.proxai.co/proxai-docs/set-global-model)\n",
    "\n",
    "You can set global default model by `px.set_model()` instead of using what ProxAI picks for you. All unspecified `px.generate_text()` calls will use this model."
   ],
   "metadata": {
    "id": "ygkY063C73pC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's define python method that doesn't specify provider_model\n",
    "def simple_request():\n",
    "  return px.generate_text(\n",
    "      'Hey AI model! This is simple request. Give an answer. Quick!',\n",
    "  ).strip().replace('\\n', ' ')[:80]\n",
    "\n",
    "# We can change default model by px.set_model\n",
    "for provider_model in px.models.list_models():\n",
    "  px.set_model(provider_model)\n",
    "  response = simple_request()\n",
    "  print(f'{provider_model} - {response}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "If_C8c5H76Ri",
    "outputId": "eee775f5-b7a5-4708-c4fc-f13b0bbf0324"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# \ud83c\udf8a Final Thoughts and Next Steps\n",
    "\n",
    "This is the basic usage of ProxAI and leads you to create enourmous project!\n",
    "\n",
    "If you want to unlock all potential of ProxAI after your toy projects and scripts, please check [\ud83d\ude80 ProxAI Advanced Usage Tutorial \ud83d\ude80](https://www.proxai.co/proxai-docs/google-colab-example) colab.\n",
    "\n",
    "ProxAI offers lots of features that gives you:\n",
    "* 5x development speed\n",
    "* Model picker and benchmarking tools\n",
    "* More control over how queries handled\n",
    "* ProxDash analytics, metrics, debuggers, cost management, and more tools"
   ],
   "metadata": {
    "id": "WXTjoov47-8R"
   }
  }
 ]
}