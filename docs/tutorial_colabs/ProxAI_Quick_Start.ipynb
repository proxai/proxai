{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/proxai/proxai/blob/main/docs/tutorial_colabs/ProxAI_Quick_Start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjbMJjs52Muk"
   },
   "source": [
    "# üèÉ‚Äç‚ôÇÔ∏è‚Äç‚û°Ô∏è ProxAI Quick Start Tutorial üèÉ‚Äç‚ôÇÔ∏è‚Äç‚û°Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cn4yLuib4RC5"
   },
   "source": [
    "## üëã Introduction\n",
    "\n",
    "Welcome to the ProxAI Quick Start Tutorial! This notebook will guide you through some of the features of the ProxAI library.\n",
    "\n",
    "In this tutorial, we will cover:\n",
    "1. ‚ö°Ô∏è Setting up ProxAI in Google Colab\n",
    "2. üîã List Available Models\n",
    "3. ü§ñ Generate Text\n",
    "4. üîÆ Set Global Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhUb737sqIIi"
   },
   "source": [
    "# 1. ‚ö°Ô∏è Setup in Google Colab\n",
    "Documentation: [proxai.co/proxai-docs](https://www.proxai.co/proxai-docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuNUNooRqOIm"
   },
   "source": [
    "## 1.1. üíª Installation\n",
    "\n",
    "First, let's install the ProxAI library from PyPI.\n",
    "\n",
    "You can track releases on the [roadmap page](https://www.proxai.co/resources/roadmap) üó∫Ô∏è.\n",
    "\n",
    "**Note:** After running the installation cell, you will likely need to **üîÑ restart the Colab session** using the button that appears in the output of the cell or by going to `Runtime > Restart session`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "av5yOW1mqBug",
    "outputId": "5c411ed0-1ea1-49e6-81ca-8ef4fff0fe1b"
   },
   "outputs": [],
   "source": [
    "!pip install proxai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yItxyArt4sK3"
   },
   "source": [
    "## 1.2. üîë API Key Management\n",
    "\n",
    "### Option 1: ProxDash Provider Connections (Recommended) ‚≠ê\n",
    "\n",
    "**Requires a ProxDash account.**\n",
    "\n",
    "1. Add your provider API keys at [proxai.co/dashboard/provider-connections](https://www.proxai.co/dashboard/provider-connections)\n",
    "2. Get your ProxDash API key from [proxai.co/dashboard/api-keys](https://www.proxai.co/dashboard/api-keys)\n",
    "3. Add `PROXDASH_API_KEY` to Colab Secrets (üîë icon in left sidebar)\n",
    "4. Run the cell below\n",
    "\n",
    "ProxAI will automatically fetch all provider keys from your dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUzEyL3PqcN0",
    "outputId": "c35a5e34-064a-4483-c4d6-c1051ba8889c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "try:\n",
    "    os.environ['PROXDASH_API_KEY'] = userdata.get('PROXDASH_API_KEY')\n",
    "    print(\"‚úÖ ProxDash API key loaded!\")\n",
    "    print(\"   ProxAI will automatically fetch provider keys from your dashboard.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è ProxDash API key not found: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Option 2: Direct API Key Management\n\n**No ProxDash account required.**\n\n1. Add each provider's API key to Colab Secrets (üîë icon in left sidebar): `OPENAI_API_KEY`, `GEMINI_API_KEY`, `ANTHROPIC_API_KEY`, etc.\n2. Refer to the [Provider Integrations documentation](https://www.proxai.co/proxai-docs/provider-integrations) for all environment key names\n3. Uncomment and run the cell below"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# OPTIONAL:\n# import os\n# from google.colab import userdata\n# from dataclasses import asdict\n# from pprint import pprint\n\n# API_KEY_LIST = [\n#     'ANTHROPIC_API_KEY',\n#     'CO_API_KEY',\n#     'DATABRICKS_TOKEN',\n#     'DATABRICKS_HOST',\n#     'DEEPSEEK_API_KEY',\n#     'GEMINI_API_KEY',\n#     'XAI_API_KEY',\n#     'HF_TOKEN',\n#     'MISTRAL_API_KEY',\n#     'OPENAI_API_KEY',\n#     'PROXDASH_API_KEY',\n# ]\n\n# print(\"üîê Attempting to load API keys from Colab secrets...\")\n# for api_key_name in API_KEY_LIST:\n#   try:\n#     os.environ[api_key_name] = userdata.get(api_key_name)\n#     print(f\"  ‚úÖ Successfully loaded {api_key_name}\")\n#   except userdata.SecretNotFoundError:\n#     print(f\"  ‚ö†Ô∏è Secret for {api_key_name} not found. Skipping.\")\n#   except Exception as e:\n#     print(f\"  ‚ùå An error occurred while loading {api_key_name}: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. ‚ñ∂Ô∏è Import ProxAI\n",
    "\n",
    "Ready to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dsx0B36W5NFe"
   },
   "outputs": [],
   "source": [
    "import proxai as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. üîã List Available Models\n",
    "\n",
    "Documentation: [proxai.co/proxai-docs/available-models](https://www.proxai.co/proxai-docs/available-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB_CFueU5RUy"
   },
   "source": [
    "## 2.1. ü™õ Simple Usage\n",
    "\n",
    "Let's list available models in our session! üéâ \\\n",
    "**Note:** This can take for a while for the first run but the results are cached and it will be fast for other runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JAwC8WLW5TZv",
    "outputId": "092b97e5-5c35-418d-88d6-147397f4e02f"
   },
   "outputs": [],
   "source": [
    "provider_models = px.models.list_models()\n",
    "for provider_model in provider_models:\n",
    "  print(f'{provider_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dAVv5Ld5VAN"
   },
   "source": [
    "## 2.2. üî≠ Different Model Sizes\n",
    "\n",
    "It is possible to filter out models according to ProxAI sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z3zKDEnV5Vfs",
    "outputId": "fe5af2b0-745f-4166-b626-d7cafbb2568b"
   },
   "outputs": [],
   "source": [
    "provider_models = px.models.list_models(model_size='small')\n",
    "print('ü•ö Small models:')\n",
    "for provider_model in provider_models:\n",
    "  print(f'{provider_model.provider:>25} - {provider_model.model}')\n",
    "\n",
    "provider_models = px.models.list_models(model_size='medium')\n",
    "print('üê£ Medium models:')\n",
    "for provider_model in provider_models:\n",
    "  print(f'{provider_model.provider:>25} - {provider_model.model}')\n",
    "\n",
    "provider_models = px.models.list_models(model_size='large')\n",
    "print('üê• Large models:')\n",
    "for provider_model in provider_models:\n",
    "  print(f'{provider_model.provider:>25} - {provider_model.model}')\n",
    "\n",
    "provider_models = px.models.list_models(model_size='largest')\n",
    "print('üêì Largest models of each provider:')\n",
    "for provider_model in provider_models:\n",
    "  print(f'{provider_model.provider:>25} - {provider_model.model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fevDRQa65jOa"
   },
   "source": [
    "# 3. ü§ñ Generate Text\n",
    "\n",
    "Documentation: [proxai.co/proxai-docs/generate-text](https://www.proxai.co/proxai-docs/generate-text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98ExB5P65jz-"
   },
   "source": [
    "## 3.1. üê∂ The Simplest Usage\n",
    "\n",
    "You can directly call `px.generate_text()` without any additional paramters. ProxAI picks default model or fallback models if default model is not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BiJcBYYp5oCJ",
    "outputId": "6b40bbe1-467e-488b-e74a-f027b0acbcff"
   },
   "outputs": [],
   "source": [
    "response = px.generate_text('Hello! Which model are you?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtJSwNzV5tZN"
   },
   "source": [
    "## 3.2. ‚úèÔ∏è Setting Provider Model\n",
    "\n",
    "You can specify `provider_model` parameter for `px.generate_text()` as `(provider, model)` tuple of strings.\n",
    "* Check [Provider Integrations documentation](https://www.proxai.co/proxai-docs/provider-integrations) to see all available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KlqvKC7R5uHY",
    "outputId": "17113150-e4ad-45fc-f07a-9d1283c30d0a"
   },
   "outputs": [],
   "source": [
    "print('‚úèÔ∏è Tuple provider_model value:')\n",
    "response = px.generate_text(\n",
    "    'Hello! Which model are you?',\n",
    "    provider_model=('claude', 'haiku-4.5'))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rOS-GeJ6V8V"
   },
   "source": [
    "## 3.3. üí¨ Additional Features\n",
    "\n",
    "You can use `system`, `messages`, `temperature`, `stop`, and many more on `px.generate_text()`.\n",
    "* Check [Generate Text documentation](https://www.proxai.co/proxai-docs/generate-text) to see all available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2dgwvr57HE9",
    "outputId": "314d2d52-cf04-48a6-f818-993dc04a1c25"
   },
   "outputs": [],
   "source": [
    "response = px.generate_text(\n",
    "    system=\"Try to impersonate Italian America Chef. Try to use lot's of italian words.\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello AI Model!\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Buongiorno!\"},\n",
    "        {\"role\": \"user\", \"content\": \"How are you today?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Molto Bene! How are you amico?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you recomend me Italian restaurants in NYC?\"}\n",
    "    ],\n",
    "    max_tokens=1000,\n",
    "    temperature=0.7,\n",
    "    stop=[\"\\n\"],\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygkY063C73pC"
   },
   "source": [
    "# 4. üîÆ Set Global Model\n",
    "\n",
    "Documentation: [proxai.co/proxai-docs/set-global-model](https://www.proxai.co/proxai-docs/set-global-model)\n",
    "\n",
    "You can set global default model by `px.set_model()` instead of using what ProxAI picks for you. All unspecified `px.generate_text()` calls will use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "If_C8c5H76Ri",
    "outputId": "eee775f5-b7a5-4708-c4fc-f13b0bbf0324"
   },
   "outputs": [],
   "source": [
    "# Let's define python method that doesn't specify provider_model\n",
    "def simple_request():\n",
    "  return px.generate_text(\n",
    "      'Hey AI model! This is simple request. Give an answer. Quick!',\n",
    "  ).strip().replace('\\n', ' ')[:80]\n",
    "\n",
    "# We can change default model by px.set_model\n",
    "for provider_model in px.models.list_models():\n",
    "  px.set_model(provider_model)\n",
    "  response = simple_request()\n",
    "  print(f'{provider_model} - {response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXTjoov47-8R"
   },
   "source": [
    "# üéä Final Thoughts and Next Steps\n",
    "\n",
    "This is the basic usage of ProxAI and leads you to create enourmous project!\n",
    "\n",
    "If you want to unlock all potential of ProxAI after your toy projects and scripts, please check [üöÄ ProxAI Advanced Usage Tutorial üöÄ](https://www.proxai.co/proxai-docs/google-colab-example) colab.\n",
    "\n",
    "ProxAI offers lots of features that gives you:\n",
    "* 5x development speed\n",
    "* Model picker and benchmarking tools\n",
    "* More control over how queries handled\n",
    "* ProxDash analytics, metrics, debuggers, cost management, and more tools"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOyNKDPrfr+1GrHhWdycZPt",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}