{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "011664ff-ffcb-4f9f-9a8d-77b95c37a3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/osmanaka/projects/proxai/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import proxai as px\n",
    "import proxai.types as px_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "829780ef-7ac4-4e6b-9c57-b2e827643899",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = f'{Path.home()}/proxai_cache/'\n",
    "logging_path = f'{Path.home()}/proxai_log/math_problems/'\n",
    "os.makedirs(cache_path, exist_ok=True)\n",
    "os.makedirs(logging_path, exist_ok=True)\n",
    "px.connect(\n",
    "    cache_options=px_types.CacheOptions(\n",
    "        path=cache_path,\n",
    "        retry_if_error_cached=True),\n",
    "    logging_path=logging_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d391598a-4776-444e-96bb-e65d9b282208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/thedevastator/mathematical-problems-dataset-various-mathematic\n",
    "TEST_DATA = [\n",
    "  {'answer': '5',\n",
    "   'question': 'Suppose 12*q + 42 = q + 42. Solve q = 22*t - 0*t - 110 for t.'},\n",
    "  {'answer': '-4',\n",
    "   'question': 'Suppose -3*p = -p + m + 60, 3*m + 151 = -5*p. Let u(d) = 2*d**2 '\n",
    "               '+ 58*d + 9. Let s be u(p). Solve 3*j = -s - 3 for j.'},\n",
    "  {'answer': '4',\n",
    "   'question': 'Suppose 8*b - 6*b - 2*q = 16, 0 = q + 5. Let k be (12 - 7 - 8) '\n",
    "               '+ 3. Suppose h - 32 = -h + 2*g, -5*g - 20 = 0. Solve b*s + k*s '\n",
    "               '= h for s.'},\n",
    "  {'answer': '0',\n",
    "   'question': 'Let t = -10 - -10. Let v(j) = j**2 + 53*j + 285. Let g be '\n",
    "               'v(-47). Solve 0 = -t*k - g*k for k.'},\n",
    "  {'answer': '-3',\n",
    "   'question': 'Let t(n) = -n + 2. Suppose 4*c = 5*b, -7*c + 5*b = -9*c. Let a '\n",
    "               'be t(c). Solve -a*d - 2*d = 12 for d.'},\n",
    "  {'answer': '-3',\n",
    "   'question': 'Let f(k) be the first derivative of -k**3/3 + 2*k**2 - k + 18. '\n",
    "               'Let y be f(3). Suppose -y = 2*r - 2*q, 3*r - 3*q = 2*r - 11. '\n",
    "               'Solve -1 + 13 = -r*m for m.'},\n",
    "  {'answer': '-2',\n",
    "   'question': 'Let w = -4494 + 4515. Solve 3*o + w = 15 for o.'},\n",
    "  {'answer': '3',\n",
    "   'question': 'Let r(h) = h**3 + 22*h**2 - 26*h - 59. Let d be r(-23). Solve 6 '\n",
    "               '= -8*t + d*t for t.'},\n",
    "  {'answer': '3',\n",
    "   'question': 'Let w(u) = -2763*u - 13815. Let v be w(-5). Let g(q) = q**3 - '\n",
    "               '4*q**2 + 2*q + 3. Let m be g(3). Solve v = -m*y - y + 3 for y.'},\n",
    "  {'answer': '2',\n",
    "   'question': 'Let q = 123 - 119. Suppose -q*u - 5*i + 5 = 0, -u - 8 = -5*i - '\n",
    "               '3. Solve u = 3*z - 5*z + 4 for z.'},\n",
    "  {'answer': '-1',\n",
    "   'question': 'Let j(k) = 3*k**2 + 7*k - 12. Let t be j(2). Let q = -12 + t. '\n",
    "               'Solve q*g - 2 = -4 for g.'},\n",
    "  {'answer': '3',\n",
    "   'question': 'Suppose 2*r - 5*p + 47 = 0, r + 5*p = -7 - 24. Let u = -24 - r. '\n",
    "               'Solve -z - u*z = -9 for z.'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e0b455-da72-4e09-bb72-54675b3eead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_GET_ANSWER_PROVIDER_CALL = 0\n",
    "_GET_ANSWER_CACHE_HIT = 0\n",
    "_EXTRACT_PROVIDER_CALL = 0\n",
    "_EXTRACT_CACHE_HIT = 0\n",
    "def print_cache_hit():\n",
    "    print(f'{_GET_ANSWER_PROVIDER_CALL=}')\n",
    "    print(f'{_GET_ANSWER_CACHE_HIT=}')\n",
    "    print(f'{_EXTRACT_PROVIDER_CALL=}')\n",
    "    print(f'{_EXTRACT_CACHE_HIT=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62da5744-fc63-42b7-acda-c02eb7675541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question):\n",
    "    global _GET_ANSWER_PROVIDER_CALL, _GET_ANSWER_CACHE_HIT\n",
    "    logging_record = px.generate_text(\n",
    "        prompt=f\"\"\"\\\n",
    "Can you give me exactly one integer answer to the following question? \\\n",
    "Nothing else, just the answer.\n",
    "Question: {question}\"\"\",\n",
    "        extensive_return=True,\n",
    "        unique_response_limit=3)\n",
    "    if logging_record.response_source == px_types.ResponseSource.PROVIDER:\n",
    "        _GET_ANSWER_PROVIDER_CALL += 1\n",
    "    else:\n",
    "        _GET_ANSWER_CACHE_HIT += 1\n",
    "    return logging_record.response_record.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0167b9a-567c-43c6-838e-f62d013aa072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_answer(TEST_DATA[0]['question']))\n",
    "# print_cache_hit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d13bfd4-3715-445a-bf83-5f330c117e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numerical_result(answer):\n",
    "    global _EXTRACT_PROVIDER_CALL, _EXTRACT_CACHE_HIT\n",
    "    logging_record = px.generate_text(\n",
    "        model=(px_types.Provider.OPENAI, px_types.OpenAIModel.GPT_4_TURBO_PREVIEW),\n",
    "        unique_response_limit=1,\n",
    "        extensive_return=True,\n",
    "        system=('You are returning single numerical result. '\n",
    "                'Just one single numerical result. Nothing else.'),\n",
    "        messages=[\n",
    "            {'role': 'user',\n",
    "             'content': ('Give me numerical value from following sentences.\\n'\n",
    "                         'Sentence: \"\"\"The answer is 37.\"\"\"')},\n",
    "            {'role': 'assistant',\n",
    "             'content': '37'},\n",
    "            {'role': 'user',\n",
    "             'content': ('Give me numerical value from following sentences.\\n'\n",
    "                         'Sentence: \"\"\"-2.37 is the answer.\\n'\n",
    "                         'Are there anything that I can help you?\"\"\"')},\n",
    "            {'role': 'assistant',\n",
    "             'content': '-2.37'},\n",
    "            {'role': 'user',\n",
    "             'content': ('Give me numerical value from following sentences.\\n'\n",
    "                         'Sentence: \"\"\"798\"\"\"')},\n",
    "            {'role': 'assistant',\n",
    "             'content': '798'},\n",
    "            {'role': 'user',\n",
    "             'content': ('Give me numerical value from following sentences.\\n'\n",
    "                         f'Sentence: \"\"\"{answer}\"\"\"')}])\n",
    "    if logging_record.response_source == px_types.ResponseSource.PROVIDER:\n",
    "        _EXTRACT_PROVIDER_CALL += 1\n",
    "    else:\n",
    "        _EXTRACT_CACHE_HIT += 1\n",
    "    try:\n",
    "        return str(int(logging_record.response_record.response))\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4ebe9-4cdc-4f73-a166-3b5daf4b028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(extract_numerical_result('Yes, there is the result: 16'))\n",
    "# print_cache_hit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3524db16-4de8-4712-8553-6eb1322256f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_for_question(question, answer, try_count):\n",
    "    question_result = {'correct': 0, 'incorrect': 0, 'error': 0}\n",
    "    for _ in range(try_count):\n",
    "        try:\n",
    "            result = get_answer(question)\n",
    "            result = extract_numerical_result(result)\n",
    "            if result == answer:\n",
    "                question_result['correct'] = True\n",
    "                return question_result\n",
    "            question_result['incorrect'] += 1\n",
    "        except Exception as e:\n",
    "            question_result['error'] += 1\n",
    "    return question_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4f2a1-8acc-4abd-bf0e-ec37c3c29205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_cache_hit()\n",
    "# px.set_model(generate_text=(px_types.Provider.COHERE, px_types.CohereModel.COMMAND))\n",
    "# pprint(get_result_for_question(TEST_DATA[0]['question'], TEST_DATA[0]['answer'], 3))\n",
    "# print_cache_hit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0649b3b8-ba0e-48f0-9589-3678a0e704f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_math_questions(try_count, verbose=False):\n",
    "    eval_result = {'correct': 0, 'incorrect': 0, 'error': 0, 'all_results': []}\n",
    "    for idx, test in enumerate(TEST_DATA):\n",
    "        if verbose:\n",
    "            print(f'{idx+1}/{len(TEST_DATA)}')\n",
    "        question_result = get_result_for_question(\n",
    "            question=test['question'],\n",
    "            answer=test['answer'],\n",
    "            try_count=try_count)\n",
    "        if question_result['correct']:\n",
    "            eval_result['correct'] += 1\n",
    "            eval_result['all_results'].append('True')\n",
    "        else:\n",
    "            if question_result['error'] == try_count:\n",
    "                eval_result['error'] += 1\n",
    "                eval_result['all_results'].append('Error')\n",
    "            else:\n",
    "                eval_result['incorrect'] += 1\n",
    "                eval_result['all_results'].append('False')\n",
    "    return eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792e5e5-f52c-40a5-a524-62979d377ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_cache_hit()\n",
    "# px.set_model(generate_text=(px_types.Provider.COHERE, px_types.CohereModel.COMMAND))\n",
    "# pprint(eval_math_questions(3, verbose=True))\n",
    "# print_cache_hit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efe1bef9-59a8-49bd-831d-b6f78f8327e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(models, try_count):\n",
    "    all_results = {}\n",
    "    for provider, provider_model in models:\n",
    "        print(f'{provider:>20} | {provider_model}')\n",
    "        px.set_model(generate_text=(provider, provider_model))\n",
    "        eval_result = eval_math_questions(try_count=try_count)\n",
    "        response = (\n",
    "            f'Correct: {eval_result[\"correct\"]:2}, '\n",
    "            f'Incorrect: {eval_result[\"incorrect\"]:2}, '\n",
    "            f'Error: {eval_result[\"error\"]:2}')\n",
    "        print(response)\n",
    "        all_results[(provider, provider_model)] = eval_result['all_results']\n",
    "        print()\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a2cb273-7c2d-4473-87b5-3db3199d2384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_GET_ANSWER_PROVIDER_CALL=174\n",
      "_GET_ANSWER_CACHE_HIT=0\n",
      "_EXTRACT_PROVIDER_CALL=79\n",
      "_EXTRACT_CACHE_HIT=95\n",
      "\n",
      "              claude | claude-3-haiku-20240307\n",
      "Correct:  3, Incorrect:  9, Error:  0\n",
      "\n",
      "              claude | claude-3-opus-20240229\n",
      "Correct:  3, Incorrect:  9, Error:  0\n",
      "\n",
      "              claude | claude-3-sonnet-20240229\n",
      "Correct:  4, Incorrect:  8, Error:  0\n",
      "\n",
      "              cohere | command\n",
      "Correct:  1, Incorrect: 11, Error:  0\n",
      "\n",
      "              cohere | command-light\n",
      "Correct:  1, Incorrect: 11, Error:  0\n",
      "\n",
      "              cohere | command-light-nightly\n",
      "Correct:  0, Incorrect: 12, Error:  0\n",
      "\n",
      "              cohere | command-nightly\n",
      "Correct:  2, Incorrect: 10, Error:  0\n",
      "\n",
      "              cohere | command-r\n",
      "Correct:  1, Incorrect: 11, Error:  0\n",
      "\n",
      "          databricks | databricks-dbrx-instruct\n",
      "Correct:  2, Incorrect:  9, Error:  1\n",
      "\n",
      "          databricks | databricks-llama-2-70b-chat\n",
      "Correct:  2, Incorrect: 10, Error:  0\n",
      "\n",
      "          databricks | databricks-mixtral-8x7b-instruct\n",
      "Correct:  3, Incorrect:  7, Error:  2\n",
      "\n",
      "              gemini | models/gemini-1.0-pro\n",
      "Correct:  4, Incorrect:  8, Error:  0\n",
      "\n",
      "              gemini | models/gemini-1.0-pro-001\n",
      "Correct:  0, Incorrect: 12, Error:  0\n",
      "\n",
      "              gemini | models/gemini-1.0-pro-latest\n",
      "Correct:  0, Incorrect:  0, Error: 12\n",
      "\n",
      "              gemini | models/gemini-1.5-pro-latest\n",
      "Correct:  0, Incorrect:  2, Error: 10\n",
      "\n",
      "              gemini | models/gemini-pro\n",
      "Correct:  3, Incorrect:  7, Error:  2\n",
      "\n",
      "        hugging_face | NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\n",
      "Correct:  1, Incorrect: 10, Error:  1\n",
      "\n",
      "        hugging_face | mistralai/Mixtral-8x7B-Instruct-v0.1\n",
      "Correct:  1, Incorrect: 11, Error:  0\n",
      "\n",
      "             mistral | mistral-large-latest\n",
      "Correct:  5, Incorrect:  7, Error:  0\n",
      "\n",
      "             mistral | mistral-medium-latest\n",
      "Correct:  8, Incorrect:  4, Error:  0\n",
      "\n",
      "             mistral | mistral-small-latest\n",
      "Correct:  6, Incorrect:  6, Error:  0\n",
      "\n",
      "             mistral | open-mistral-7b\n",
      "Correct:  2, Incorrect: 10, Error:  0\n",
      "\n",
      "             mistral | open-mixtral-8x7b\n",
      "Correct:  7, Incorrect:  5, Error:  0\n",
      "\n",
      "              openai | gpt-3.5-turbo\n",
      "Correct:  4, Incorrect:  8, Error:  0\n",
      "\n",
      "              openai | gpt-4\n",
      "Correct:  4, Incorrect:  8, Error:  0\n",
      "\n",
      "              openai | gpt-4-turbo-preview\n",
      "Correct:  8, Incorrect:  4, Error:  0\n",
      "\n",
      "_GET_ANSWER_PROVIDER_CALL=710\n",
      "_GET_ANSWER_CACHE_HIT=163\n",
      "_EXTRACT_PROVIDER_CALL=287\n",
      "_EXTRACT_CACHE_HIT=586\n"
     ]
    }
   ],
   "source": [
    "print_cache_hit()\n",
    "print()\n",
    "all_results = run_test(px.models.generate_text(verbose=True), 3)\n",
    "print_cache_hit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83105b8a-5324-4bed-b5e9-ce8d15ff2fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cache_hit()\n",
    "print()\n",
    "all_results = run_test(px.models.generate_text(verbose=True), 3)\n",
    "print_cache_hit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7613f211-f457-456a-9c74-2c52604211cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_GET_ANSWER_PROVIDER_CALL=715\n",
      "_GET_ANSWER_CACHE_HIT=179\n",
      "_EXTRACT_PROVIDER_CALL=290\n",
      "_EXTRACT_CACHE_HIT=604\n",
      "1/12\n",
      "2/12\n",
      "3/12\n",
      "4/12\n",
      "5/12\n",
      "6/12\n",
      "7/12\n",
      "8/12\n",
      "9/12\n",
      "10/12\n",
      "11/12\n",
      "12/12\n",
      "{'all_results': ['False',\n",
      "                 'False',\n",
      "                 'False',\n",
      "                 'True',\n",
      "                 'Error',\n",
      "                 'Error',\n",
      "                 'Error',\n",
      "                 'Error',\n",
      "                 'Error',\n",
      "                 'Error',\n",
      "                 'Error',\n",
      "                 'Error'],\n",
      " 'correct': 1,\n",
      " 'error': 8,\n",
      " 'incorrect': 3}\n",
      "_GET_ANSWER_PROVIDER_CALL=715\n",
      "_GET_ANSWER_CACHE_HIT=186\n",
      "_EXTRACT_PROVIDER_CALL=290\n",
      "_EXTRACT_CACHE_HIT=611\n"
     ]
    }
   ],
   "source": [
    "print_cache_hit()\n",
    "px.set_model(generate_text=(px_types.Provider.GEMINI, px_types.GeminiModel.GEMINI_1_5_PRO_LATEST))\n",
    "pprint(eval_math_questions(3, verbose=True))\n",
    "print_cache_hit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
