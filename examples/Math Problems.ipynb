{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "011664ff-ffcb-4f9f-9a8d-77b95c37a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import proxai as px\n",
    "import proxai.types as px_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "829780ef-7ac4-4e6b-9c57-b2e827643899",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = f'{Path.home()}/proxai_cache/'\n",
    "logging_path = f'{Path.home()}/proxai_log/math_problems/'\n",
    "os.makedirs(cache_path, exist_ok=True)\n",
    "os.makedirs(logging_path, exist_ok=True)\n",
    "px.connect(\n",
    "    cache_options=px_types.CacheOptions(\n",
    "        path=cache_path,\n",
    "        retry_if_error_cached=True),\n",
    "    logging_path=logging_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d391598a-4776-444e-96bb-e65d9b282208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/thedevastator/mathematical-problems-dataset-various-mathematic\n",
    "TEST_DATA = [\n",
    "  {'answer': '5',\n",
    "   'question': 'Suppose 12*q + 42 = q + 42. Solve q = 22*t - 0*t - 110 for t.'},\n",
    "  {'answer': '-4',\n",
    "   'question': 'Suppose -3*p = -p + m + 60, 3*m + 151 = -5*p. Let u(d) = 2*d**2 '\n",
    "               '+ 58*d + 9. Let s be u(p). Solve 3*j = -s - 3 for j.'},\n",
    "  {'answer': '4',\n",
    "   'question': 'Suppose 8*b - 6*b - 2*q = 16, 0 = q + 5. Let k be (12 - 7 - 8) '\n",
    "               '+ 3. Suppose h - 32 = -h + 2*g, -5*g - 20 = 0. Solve b*s + k*s '\n",
    "               '= h for s.'},\n",
    "  {'answer': '0',\n",
    "   'question': 'Let t = -10 - -10. Let v(j) = j**2 + 53*j + 285. Let g be '\n",
    "               'v(-47). Solve 0 = -t*k - g*k for k.'},\n",
    "  {'answer': '-3',\n",
    "   'question': 'Let t(n) = -n + 2. Suppose 4*c = 5*b, -7*c + 5*b = -9*c. Let a '\n",
    "               'be t(c). Solve -a*d - 2*d = 12 for d.'},\n",
    "  {'answer': '-3',\n",
    "   'question': 'Let f(k) be the first derivative of -k**3/3 + 2*k**2 - k + 18. '\n",
    "               'Let y be f(3). Suppose -y = 2*r - 2*q, 3*r - 3*q = 2*r - 11. '\n",
    "               'Solve -1 + 13 = -r*m for m.'},\n",
    "  {'answer': '-2',\n",
    "   'question': 'Let w = -4494 + 4515. Solve 3*o + w = 15 for o.'},\n",
    "  {'answer': '3',\n",
    "   'question': 'Let r(h) = h**3 + 22*h**2 - 26*h - 59. Let d be r(-23). Solve 6 '\n",
    "               '= -8*t + d*t for t.'},\n",
    "  {'answer': '3',\n",
    "   'question': 'Let w(u) = -2763*u - 13815. Let v be w(-5). Let g(q) = q**3 - '\n",
    "               '4*q**2 + 2*q + 3. Let m be g(3). Solve v = -m*y - y + 3 for y.'},\n",
    "  {'answer': '2',\n",
    "   'question': 'Let q = 123 - 119. Suppose -q*u - 5*i + 5 = 0, -u - 8 = -5*i - '\n",
    "               '3. Solve u = 3*z - 5*z + 4 for z.'},\n",
    "  {'answer': '-1',\n",
    "   'question': 'Let j(k) = 3*k**2 + 7*k - 12. Let t be j(2). Let q = -12 + t. '\n",
    "               'Solve q*g - 2 = -4 for g.'},\n",
    "  {'answer': '3',\n",
    "   'question': 'Suppose 2*r - 5*p + 47 = 0, r + 5*p = -7 - 24. Let u = -24 - r. '\n",
    "               'Solve -z - u*z = -9 for z.'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62da5744-fc63-42b7-acda-c02eb7675541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question):\n",
    "    return px.generate_text(\n",
    "        prompt=f\"\"\"\\\n",
    "Can you give me exactly one integer answer to the following question? \\\n",
    "Nothing else, just the answer.\n",
    "Question: {question}\"\"\",\n",
    "        unique_response_limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0167b9a-567c-43c6-838e-f62d013aa072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{'cache_stats': {'saved_avr_response_time': 0.669426,\n",
      "                 'saved_estimated_price': 0.00075,\n",
      "                 'saved_response_token_count': 500,\n",
      "                 'saved_token_count': 500,\n",
      "                 'saved_total_response_time': 3.34713,\n",
      "                 'total_cache_hit': 5,\n",
      "                 'total_success_return': 5},\n",
      " 'provider_stats': {},\n",
      " 'providers': {'openai': {'cache_stats': {'saved_avr_response_time': 0.669426,\n",
      "                                          'saved_estimated_price': 0.00075,\n",
      "                                          'saved_response_token_count': 500,\n",
      "                                          'saved_token_count': 500,\n",
      "                                          'saved_total_response_time': 3.34713,\n",
      "                                          'total_cache_hit': 5,\n",
      "                                          'total_success_return': 5},\n",
      "                          'models': [{'model_stats': {'cache_stats': {'saved_avr_response_time': 0.669426,\n",
      "                                                                      'saved_estimated_price': 0.00075,\n",
      "                                                                      'saved_response_token_count': 500,\n",
      "                                                                      'saved_token_count': 500,\n",
      "                                                                      'saved_total_response_time': 3.34713,\n",
      "                                                                      'total_cache_hit': 5,\n",
      "                                                                      'total_success_return': 5},\n",
      "                                                      'model': {'provider': 'openai',\n",
      "                                                                'provider_model': 'gpt-3.5-turbo'},\n",
      "                                                      'provider_stats': {}},\n",
      "                                      'provider': 'openai',\n",
      "                                      'provider_model': 'gpt-3.5-turbo'}],\n",
      "                          'provider': 'openai',\n",
      "                          'provider_stats': {}}}}\n"
     ]
    }
   ],
   "source": [
    "print(get_answer(TEST_DATA[0]['question']))\n",
    "summary_data = px.get_summary(json=True)\n",
    "pprint(summary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d13bfd4-3715-445a-bf83-5f330c117e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numerical_result(answer):\n",
    "    response = px.generate_text(\n",
    "        model=(px_types.Provider.OPENAI, px_types.OpenAIModel.GPT_4_TURBO_PREVIEW),\n",
    "        unique_response_limit=1,\n",
    "        system=('You are returning single numerical result. '\n",
    "                'Just one single numerical result. Nothing else.'),\n",
    "        messages=[\n",
    "            {'role': 'user',\n",
    "             'content': ('Give me numerical value from following sentences.\\n'\n",
    "                         'Sentence: \"\"\"The answer is 37.\"\"\"')},\n",
    "            {'role': 'assistant',\n",
    "             'content': '37'},\n",
    "            {'role': 'user',\n",
    "             'content': ('Give me numerical value from following sentences.\\n'\n",
    "                         'Sentence: \"\"\"-2.37 is the answer.\\n'\n",
    "                         'Are there anything that I can help you?\"\"\"')},\n",
    "            {'role': 'assistant',\n",
    "             'content': '-2.37'},\n",
    "            {'role': 'user',\n",
    "             'content': ('Give me numerical value from following sentences.\\n'\n",
    "                         'Sentence: \"\"\"798\"\"\"')},\n",
    "            {'role': 'assistant',\n",
    "             'content': '798'},\n",
    "            {'role': 'user',\n",
    "             'content': ('Give me numerical value from following sentences.\\n'\n",
    "                         f'Sentence: \"\"\"{answer}\"\"\"')}])\n",
    "    try:\n",
    "        return str(int(response))\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4ebe9-4cdc-4f73-a166-3b5daf4b028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_numerical_result('Yes, there is the result: 16'))\n",
    "summary_data = px.get_summary(json=True)\n",
    "pprint(summary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3524db16-4de8-4712-8553-6eb1322256f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_for_question(question, answer, try_count):\n",
    "    question_result = {'correct': 0, 'incorrect': 0, 'error': 0}\n",
    "    for _ in range(try_count):\n",
    "        try:\n",
    "            result = get_answer(question)\n",
    "            result = extract_numerical_result(result)\n",
    "            if result == answer:\n",
    "                question_result['correct'] = True\n",
    "                return question_result\n",
    "            question_result['incorrect'] += 1\n",
    "        except Exception as e:\n",
    "            question_result['error'] += 1\n",
    "    return question_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4f2a1-8acc-4abd-bf0e-ec37c3c29205",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.set_model(generate_text=(px_types.Provider.OPENAI, px_types.OpenAIModel.GPT_4))\n",
    "pprint(get_result_for_question(TEST_DATA[0]['question'], TEST_DATA[0]['answer'], 3))\n",
    "summary_data = px.get_summary(json=True)\n",
    "pprint(summary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0649b3b8-ba0e-48f0-9589-3678a0e704f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_math_questions(try_count, verbose=False):\n",
    "    eval_result = {'correct': 0, 'incorrect': 0, 'error': 0, 'all_results': []}\n",
    "    for idx, test in enumerate(TEST_DATA):\n",
    "        if verbose:\n",
    "            print(f'{idx+1}/{len(TEST_DATA)}')\n",
    "        question_result = get_result_for_question(\n",
    "            question=test['question'],\n",
    "            answer=test['answer'],\n",
    "            try_count=try_count)\n",
    "        if question_result['correct']:\n",
    "            eval_result['correct'] += 1\n",
    "            eval_result['all_results'].append('True')\n",
    "        else:\n",
    "            if question_result['error'] == try_count:\n",
    "                eval_result['error'] += 1\n",
    "                eval_result['all_results'].append('Error')\n",
    "            else:\n",
    "                eval_result['incorrect'] += 1\n",
    "                eval_result['all_results'].append('False')\n",
    "    return eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792e5e5-f52c-40a5-a524-62979d377ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.set_model(generate_text=(px_types.Provider.OPENAI, px_types.OpenAIModel.GPT_4))\n",
    "pprint(eval_math_questions(3, verbose=True))\n",
    "summary_data = px.get_summary(json=True)\n",
    "pprint(summary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efe1bef9-59a8-49bd-831d-b6f78f8327e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(models, try_count):\n",
    "    all_results = {}\n",
    "    start_summary = px.get_summary()\n",
    "    for provider, provider_model in models:\n",
    "        if provider != 'openai':\n",
    "            continue\n",
    "        model_start_summary = px.get_summary()\n",
    "        print(f'{provider:>20} | {provider_model}')\n",
    "        px.set_model(generate_text=(provider, provider_model))\n",
    "        eval_result = eval_math_questions(try_count=try_count)\n",
    "        all_results[(provider, provider_model)] = eval_result['all_results']\n",
    "        response = (\n",
    "            f'Correct: {eval_result[\"correct\"]:2}, '\n",
    "            f'Incorrect: {eval_result[\"incorrect\"]:2}, '\n",
    "            f'Error: {eval_result[\"error\"]:2}')\n",
    "        print(response)\n",
    "        diff_summary = px.get_summary() - model_start_summary\n",
    "        print(f'Cache Hit     : {diff_summary.cache_stats.total_cache_hit}')\n",
    "        print(f'Provider Call : {diff_summary.provider_stats.total_queries}')\n",
    "        print(f'Saved dolar amout via cache : {diff_summary.cache_stats.saved_estimated_price:.2} $')\n",
    "        print(f'Charged dolar amount        : {diff_summary.provider_stats.estimated_price:.2} $')\n",
    "        print()\n",
    "    diff_summary = px.get_summary() - start_summary\n",
    "    print(f'TOTAL Cache Hit     : {diff_summary.cache_stats.total_cache_hit}')\n",
    "    print(f'TOTAL Provider Call : {diff_summary.provider_stats.total_queries}')\n",
    "    print(f'TOTAL Saved dolar amout via cache : {diff_summary.cache_stats.saved_estimated_price:.2} $')\n",
    "    print(f'TOTAL Charged dolar amount        : {diff_summary.provider_stats.estimated_price:.2} $')\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a2cb273-7c2d-4473-87b5-3db3199d2384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              openai | gpt-3.5-turbo\n",
      "Correct:  4, Incorrect:  8, Error:  0\n",
      "Cache Hit     : 64\n",
      "Provider Call : 0\n",
      "Saved dolar amout via cache : 0.1 $\n",
      "Charged dolar amount        : 0.0 $\n",
      "\n",
      "              openai | gpt-4\n",
      "Correct:  4, Incorrect:  8, Error:  0\n",
      "Cache Hit     : 66\n",
      "Provider Call : 0\n",
      "Saved dolar amout via cache : 0.3 $\n",
      "Charged dolar amount        : 0.0 $\n",
      "\n",
      "              openai | gpt-4-turbo-preview\n",
      "Correct:  8, Incorrect:  4, Error:  0\n",
      "Cache Hit     : 48\n",
      "Provider Call : 0\n",
      "Saved dolar amout via cache : 0.14 $\n",
      "Charged dolar amount        : 0.0 $\n",
      "\n",
      "TOTAL Cache Hit     : 178\n",
      "TOTAL Provider Call : 0\n",
      "TOTAL Saved dolar amout via cache : 0.54 $\n",
      "TOTAL Charged dolar amount        : 0.0 $\n"
     ]
    }
   ],
   "source": [
    "all_results = run_test(px.models.generate_text(verbose=True), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3a465-b601-4f92-9d94-2cf446a09e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = run_test(px.models.generate_text(verbose=True), 3)\n",
    "summary_data = px.get_summary(json=True)\n",
    "pprint(summary_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
